<!DOCTYPE html>
<html>
  <head>
    <title>§2 CNN</title>
    <meta charset="utf-8">

    <!-- KaTeX -->
    <link rel="stylesheet" href="./layouts/katex/katex.min.css">
    <script defer src="./layouts/katex/katex.min.js"></script>
    <script defer src="./layouts/katex/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
                delimiters: [
                    {left: "$$", right: "$$", display: true},
                    {left: "$", right: "$", display: false}
                ]
            });
        });
    </script>

    <!-- tabsets -->
    <link rel="stylesheet" href="./layouts/tabsets/tabsets.min.css">
    <script defer src="./layouts/tabsets/tabsets.min.js"></script>

    <link rel="stylesheet" href="./layouts/style.css" />
  </head>
  <body>
    <textarea id="source">

class: center, middle

<!-- copy and paste down below -->

## §2 CNN

MNIST is here for the purpose of introducing the pipeline of Machine Learning; AlexNet showed the power of cuda and deep neural network; ResNet is the most popular CNN to this day and residual connections are also used in Transformers.

| [CNN Explainer](https://poloclub.github.io/cnn-explainer/) | [Handwritten Digit Recognizer CNN](https://www.shadertoy.com/view/msVXWD) |

---

### §2.1 MNIST

| [mnist (torch)](https://github.com/pytorch/examples/tree/main/mnist) | [_What is torch.nn really?_](https://pytorch.org/tutorials/beginner/nn_tutorial.html) | [MNIST Benchmark](https://paperswithcode.com/sota/image-classification-on-mnist) | [_Deep Neural Nets: 33 years ago and 33 years from now_](https://karpathy.github.io/2022/03/14/lecun1989/) |

<center><img src="https://production-media.paperswithcode.com/datasets/MNIST-0000000001-2e09631a_09liOmx.jpg"></center>

---

In [mnist (torch)](https://github.com/pytorch/examples/tree/main/mnist):

```python
class Net():
    def __init__():
    def forward():

def train():

def test():

def main():

if __name__ == '__main__':
    main()

```

---

```python
class Net(nn.Module):
    def __init__(self):
        ...

    def forward(self, x):
        ...
        output = F.log_softmax(x, dim=1)
        return output
```

[F.log_softmax](https://pytorch.org/docs/stable/generated/torch.nn.functional.log_softmax.html), [F.nll_loss](https://pytorch.org/docs/stable/generated/torch.nn.functional.nll_loss.html), [F.cross_entropy](https://pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html)

```python
pred = torch.randn(16, 10)# [batch_size, num_classes]
target = torch.randint(10, (16,))# [batch_size,]
print(F.nll_loss(F.log_softmax(pred, dim=1), target))
print(F.cross_entropy(pred, target))
```

will get:

```Bash
tensor(2.6026)
tensor(2.6026)# same result
```

---

```python
summary(Net(), input_size=(16, 1, 28, 28))# [batch_size, C, H, W]
```

will get:

```Bash
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      [16, 10]                  --
├─Conv2d: 1-1                            [16, 32, 26, 26]          320
├─Conv2d: 1-2                            [16, 64, 24, 24]          18,496
├─Dropout: 1-3                           [16, 64, 12, 12]          --
├─Linear: 1-4                            [16, 128]                 1,179,776
├─Dropout: 1-5                           [16, 128]                 --
├─Linear: 1-6                            [16, 10]                  1,290
==========================================================================================
Total params: 1,199,882
Trainable params: 1,199,882
Non-trainable params: 0
Total mult-adds (M): 192.82
==========================================================================================
Input size (MB): 0.05
Forward/backward pass size (MB): 7.51
Params size (MB): 4.80
Estimated Total Size (MB): 12.35
==========================================================================================
```

---

```python
def train(args, model, device, train_loader, optimizer, epoch):
    # set the model to training mode: activate dropout and batch normalization.
    model.train()
    # go through each batch.
    for batch_idx, (data, target) in enumerate(train_loader):
        # put data and target to device.
        data, target = data.to(device), target.to(device)
        # the optimizer's gradient is reset to 0.
        optimizer.zero_grad()
        # forward pass.
        output = model(data)
        # calculate loss.
        loss = F.nll_loss(output, target)
        # calculate the gradients.
        loss.backward()
        # backward propagation.
        optimizer.step()
        # print loss
        if batch_idx % args.log_interval == 0:
            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                epoch, batch_idx * len(data), len(train_loader.dataset),
                100. * batch_idx / len(train_loader), loss.item()))
            # if `dry_run`, only run 1 epoch.
            if args.dry_run:
                break
```

---

```python
def test(model, device, test_loader):
    # set the model to evaluation mode.
    model.eval()
    test_loss = 0
    correct = 0
    # gradient calculations are disabled.
    with torch.no_grad():
        for data, target in test_loader:
            # put data and target to device.
            data, target = data.to(device), target.to(device)
            # forward pass.
            output = model(data)
            # calculate loss, sum up batch loss.
            test_loss += F.nll_loss(output, target, reduction='sum').item()
            # get the index of the max log-probability.
            pred = output.argmax(dim=1, keepdim=True)
            # compare predicted labels with target labels.
            correct += pred.eq(target.view_as(pred)).sum().item()
    # average loss per sample.
    test_loss /= len(test_loader.dataset)
    # print
    print('\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
        test_loss, correct, len(test_loader.dataset),
        100. * correct / len(test_loader.dataset)))
```

---

```python
def main():
    # Training settings
    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')
    parser.add_argument('--batch-size', type=int, default=64, metavar='N',
                        help='input batch size for training (default: 64)')
    parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',
                        help='input batch size for testing (default: 1000)')
    parser.add_argument('--epochs', type=int, default=14, metavar='N',
                        help='number of epochs to train (default: 14)')
    parser.add_argument('--lr', type=float, default=1.0, metavar='LR',
                        help='learning rate (default: 1.0)')
    parser.add_argument('--gamma', type=float, default=0.7, metavar='M',
                        help='Learning rate step gamma (default: 0.7)')
    parser.add_argument('--no-cuda', action='store_true', default=False,
                        help='disables CUDA training')
    parser.add_argument('--no-mps', action='store_true', default=False,
                        help='disables macOS GPU training')
    parser.add_argument('--dry-run', action='store_true', default=False,
                        help='quickly check a single pass')
    parser.add_argument('--seed', type=int, default=1, metavar='S',
                        help='random seed (default: 1)')
    parser.add_argument('--log-interval', type=int, default=10, metavar='N',
                        help='how many batches to wait before logging training status')
    parser.add_argument('--save-model', action='store_true', default=False,
                        help='For Saving the current Model')
```

---

```python
    args = parser.parse_args()
    use_cuda = not args.no_cuda and torch.cuda.is_available()
    use_mps = not args.no_mps and torch.backends.mps.is_available()

    torch.manual_seed(args.seed)

    if use_cuda:
        device = torch.device("cuda")
    elif use_mps:
        device = torch.device("mps")
    else:
        device = torch.device("cpu")

    train_kwargs = {'batch_size': args.batch_size}
    test_kwargs = {'batch_size': args.test_batch_size}
    if use_cuda:
        cuda_kwargs = {'num_workers': 1,
                       'pin_memory': True,
                       'shuffle': True}
        train_kwargs.update(cuda_kwargs)
        test_kwargs.update(cuda_kwargs)
```

---

```python
    # https://pytorch.org/vision/stable/transforms.html
    transform=transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))
        ])
    # load training dataset and testing dataset
    dataset1 = datasets.MNIST('../data', train=True, download=True,
                       transform=transform)
    dataset2 = datasets.MNIST('../data', train=False,
                       transform=transform)
    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)
    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)
    # put model to device
    model = Net().to(device)
    # set optimizer and scheduler
    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)
    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)
    # train and test
    for epoch in range(1, args.epochs + 1):
        train(args, model, device, train_loader, optimizer, epoch)
        test(model, device, test_loader)
        scheduler.step()
    # save model
    if args.save_model:
        torch.save(model.state_dict(), "mnist_cnn.pt")
```

---

```Bash
python main.py
```

will get (full log see [02_mnist.log](./assets/02_mnist.log)):

```Bash
Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz
100% 9912422/9912422 [00:00<00:00, 96238958.45it/s]
Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw

Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz
100% 28881/28881 [00:00<00:00, 151799115.07it/s]
Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw

Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz
100% 1648877/1648877 [00:00<00:00, 27617389.31it/s]
Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw

Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz
100% 4542/4542 [00:00<00:00, 20180644.88it/s]
Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw
```

---

```Bash

Train Epoch: 1 [0/60000 (0%)]	Loss: 2.282550
Train Epoch: 1 [640/60000 (1%)]	Loss: 1.384441
...
Train Epoch: 1 [58880/60000 (98%)]	Loss: 0.064402
Train Epoch: 1 [59520/60000 (99%)]	Loss: 0.033435

Test set: Average loss: 0.0468, Accuracy: 9842/10000 (98%)

Train Epoch: 2 [0/60000 (0%)]	Loss: 0.098867
Train Epoch: 2 [640/60000 (1%)]	Loss: 0.016046
...
Train Epoch: 2 [58880/60000 (98%)]	Loss: 0.108346
Train Epoch: 2 [59520/60000 (99%)]	Loss: 0.108657

Test set: Average loss: 0.0327, Accuracy: 9894/10000 (99%)
...
Test set: Average loss: 0.0346, Accuracy: 9887/10000 (99%)
...
Test set: Average loss: 0.0314, Accuracy: 9891/10000 (99%)
...
Test set: Average loss: 0.0301, Accuracy: 9903/10000 (99%)
...
Test set: Average loss: 0.0301, Accuracy: 9913/10000 (99%)
...
```

---

```Bash
Test set: Average loss: 0.0293, Accuracy: 9918/10000 (99%)
...
Test set: Average loss: 0.0295, Accuracy: 9919/10000 (99%)
...
Test set: Average loss: 0.0296, Accuracy: 9915/10000 (99%)
...
Test set: Average loss: 0.0277, Accuracy: 9919/10000 (99%)
...
Test set: Average loss: 0.0284, Accuracy: 9922/10000 (99%)
...
Test set: Average loss: 0.0272, Accuracy: 9922/10000 (99%)
...
Test set: Average loss: 0.0278, Accuracy: 9921/10000 (99%)
...
Test set: Average loss: 0.0278, Accuracy: 9922/10000 (99%)
```

---

### §2.2 AlexNet: Deep Learning Revolution

[ImageNet](https://www.image-net.org/): 14,197,122 images, 21841 synsets indexed.

| [paper](https://proceedings.neurips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html) | [`torchvision.models.alexnet`](https://github.com/pytorch/vision/blob/main/torchvision/models/alexnet.py) | [AlexNet (pytorch.org)](https://pytorch.org/hub/pytorch_vision_alexnet/) |

|Methods|Do we use it today?|
|:-|:-|
|2 GPUs: written in `cuda`, split into 2 different pipelines with connection.|✔️&✖️|
|Simple activation function [ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) ($\text{ReLU} (x) = \max{(0,x)}$), instead of [Tanh](https://pytorch.org/docs/stable/generated/torch.nn.Tanh.html) ($\text{Tanh} (x) = \tanh{(x)}$) or [Sigmoid](https://pytorch.org/docs/stable/generated/torch.nn.functional.sigmoid.html) ($\sigma (x)= (1+e^{-x})^{-1}$).|✔️|
|Local response normalization|✖️|
|Overlapping pooling|✖️|
|The feature map ($C$) keeps increasing (3 $\to$ 48 $\to$ 128 $\to$ 192 $\to$ 128), while the resolution ($H$, $W$) keeps decreasing (224 $\to$ 55 $\to$ 27 $\to$ 13 $\to$ 13 $\to$ 13).|✔️|
|Kernel size keeps decreasing (11 $\to$ 5 $\to$ 3 $\to$ 3 $\to$ 3)|✖️, same kernel size 3, see ResNet below|
|Multiple linear layers. (take most of the parameters, 55M/61M)|✖️|
|Data augmentation (Image translations and horizontal reflections, color jitter)|[✔️](https://pytorch.org/vision/stable/transforms.html), actually more data|
|Dropout|✔️|

---

```python
summary(AlexNet(), input_size=(16, 3, 224, 224))
```

will get:

```Bash
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
AlexNet                                  [16, 1000]                --
├─Sequential: 1-1                        [16, 256, 6, 6]           --
│    └─Conv2d: 2-1                       [16, 64, 55, 55]          23,296
│    └─ReLU: 2-2                         [16, 64, 55, 55]          --
│    └─MaxPool2d: 2-3                    [16, 64, 27, 27]          --
│    └─Conv2d: 2-4                       [16, 192, 27, 27]         307,392
│    └─ReLU: 2-5                         [16, 192, 27, 27]         --
│    └─MaxPool2d: 2-6                    [16, 192, 13, 13]         --
│    └─Conv2d: 2-7                       [16, 384, 13, 13]         663,936
│    └─ReLU: 2-8                         [16, 384, 13, 13]         --
│    └─Conv2d: 2-9                       [16, 256, 13, 13]         884,992
│    └─ReLU: 2-10                        [16, 256, 13, 13]         --
│    └─Conv2d: 2-11                      [16, 256, 13, 13]         590,080
│    └─ReLU: 2-12                        [16, 256, 13, 13]         --
│    └─MaxPool2d: 2-13                   [16, 256, 6, 6]           --
```

---

```Bash
├─AdaptiveAvgPool2d: 1-2                 [16, 256, 6, 6]           --
├─Sequential: 1-3                        [16, 1000]                --
│    └─Dropout: 2-14                     [16, 9216]                --
│    └─Linear: 2-15                      [16, 4096]                37,752,832
│    └─ReLU: 2-16                        [16, 4096]                --
│    └─Dropout: 2-17                     [16, 4096]                --
│    └─Linear: 2-18                      [16, 4096]                16,781,312
│    └─ReLU: 2-19                        [16, 4096]                --
│    └─Linear: 2-20                      [16, 1000]                4,097,000
==========================================================================================
Total params: 61,100,840
Trainable params: 61,100,840
Non-trainable params: 0
Total mult-adds (G): 11.43
==========================================================================================
Input size (MB): 9.63
Forward/backward pass size (MB): 63.26
Params size (MB): 244.40
Estimated Total Size (MB): 317.29
==========================================================================================
```

---

### §2.3 ResNet: Deeper

| [paper](https://arxiv.org/abs/1512.03385) | [`torchvision.models.resnet`](https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py) | [ResNet (pytorch.org)](https://pytorch.org/hub/pytorch_vision_resnet/) |

Problem: With deeper layers, the loss goes upwards (see Fig.1 of the paper), but even if all the added layers are identity functions, the loss would be the same.

|Methods|Do we use it today?|
|:-|:-|
|Residual connections to learn the differences and go __deeper__ (50, 101, 152, 1202 layers, with 0.85M parameters to 19.4M parameters)|✔️|
|The feature map ($C$) keeps increasing (64 $\to$ 128 $\to$ 256 $\to$ 512), while the number of the resolution ($H$, $W$) keeps decreasing (224 $\to$ 112 $\to$ 56 $\to$ 28 $\to$ 14 $\to$ 7 $\to$ 1).|✔️|
|Stride 2 convolution kernel, instead of pooling|✔️|
|Bottleneck building block: $1 \times 1$ convolution kernel|✔️&✖️|
|Adopt batch normalization (BN) right after each convolution and before activation|✔️&✖️, ongoing debate|

---

Basically residual connections are:

```python
class Res(nn.Module):
    def __init__(self):
        super.__init__()
        ...
    
    def forward(self, x):
        residual = x
        x = ...(x)
        x += residual
        residual = x
        x = ...(x)
        x += residual
        return x
```

We will see residual connections in Transformers.

---

In [`torchvision.models.resnet`](https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py):

```python
def conv3x3():

def conv1x1():

class BasicBlock():
    def __init__():
    def forward():

class Bottleneck():
    def __init__():
    def forward():

class ResNet():
    def __init__():
    def _make_layer():
    def _forward_impl():
    def forward():

class ResNet18_Weights():
...

def resnet18():
...
```

---

```python
from torchvision.models.resnet import resnet18

model = resnet18()
summary(model, input_size=(16, 3, 224, 224))
```

or

```python
model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)
summary(model, input_size=(16, 3, 224, 224))
```

will get:

```Bash
Downloading: "https://github.com/pytorch/vision/zipball/v0.10.0" to /root/.cache/torch/hub/v0.10.0.zip
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Downloading: "https://download.pytorch.org/models/resnet18-f37072fd.pth" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth
100%|██████████| 44.7M/44.7M [00:00<00:00, 114MB/s]
```

---

```Bash
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
ResNet                                   [16, 1000]                --
├─Conv2d: 1-1                            [16, 64, 112, 112]        9,408
├─BatchNorm2d: 1-2                       [16, 64, 112, 112]        128
├─ReLU: 1-3                              [16, 64, 112, 112]        --
├─MaxPool2d: 1-4                         [16, 64, 56, 56]          --
├─Sequential: 1-5                        [16, 64, 56, 56]          --
│    └─BasicBlock: 2-1                   [16, 64, 56, 56]          --
│    │    └─Conv2d: 3-1                  [16, 64, 56, 56]          36,864
│    │    └─BatchNorm2d: 3-2             [16, 64, 56, 56]          128
│    │    └─ReLU: 3-3                    [16, 64, 56, 56]          --
│    │    └─Conv2d: 3-4                  [16, 64, 56, 56]          36,864
│    │    └─BatchNorm2d: 3-5             [16, 64, 56, 56]          128
│    │    └─ReLU: 3-6                    [16, 64, 56, 56]          --
│    └─BasicBlock: 2-2                   [16, 64, 56, 56]          --
│    │    └─Conv2d: 3-7                  [16, 64, 56, 56]          36,864
│    │    └─BatchNorm2d: 3-8             [16, 64, 56, 56]          128
│    │    └─ReLU: 3-9                    [16, 64, 56, 56]          --
│    │    └─Conv2d: 3-10                 [16, 64, 56, 56]          36,864
│    │    └─BatchNorm2d: 3-11            [16, 64, 56, 56]          128
│    │    └─ReLU: 3-12                   [16, 64, 56, 56]          --
```

---

```Bash
├─Sequential: 1-6                        [16, 128, 28, 28]         --
│    └─BasicBlock: 2-3                   [16, 128, 28, 28]         --
│    │    └─Conv2d: 3-13                 [16, 128, 28, 28]         73,728
│    │    └─BatchNorm2d: 3-14            [16, 128, 28, 28]         256
│    │    └─ReLU: 3-15                   [16, 128, 28, 28]         --
│    │    └─Conv2d: 3-16                 [16, 128, 28, 28]         147,456
│    │    └─BatchNorm2d: 3-17            [16, 128, 28, 28]         256
│    │    └─Sequential: 3-18             [16, 128, 28, 28]         8,448
│    │    └─ReLU: 3-19                   [16, 128, 28, 28]         --
│    └─BasicBlock: 2-4                   [16, 128, 28, 28]         --
│    │    └─Conv2d: 3-20                 [16, 128, 28, 28]         147,456
│    │    └─BatchNorm2d: 3-21            [16, 128, 28, 28]         256
│    │    └─ReLU: 3-22                   [16, 128, 28, 28]         --
│    │    └─Conv2d: 3-23                 [16, 128, 28, 28]         147,456
│    │    └─BatchNorm2d: 3-24            [16, 128, 28, 28]         256
│    │    └─ReLU: 3-25                   [16, 128, 28, 28]         --
├─Sequential: 1-7                        [16, 256, 14, 14]         --
│    └─BasicBlock: 2-5                   [16, 256, 14, 14]         --
│    │    └─Conv2d: 3-26                 [16, 256, 14, 14]         294,912
│    │    └─BatchNorm2d: 3-27            [16, 256, 14, 14]         512
│    │    └─ReLU: 3-28                   [16, 256, 14, 14]         --
│    │    └─Conv2d: 3-29                 [16, 256, 14, 14]         589,824
│    │    └─BatchNorm2d: 3-30            [16, 256, 14, 14]         512
│    │    └─Sequential: 3-31             [16, 256, 14, 14]         33,280
│    │    └─ReLU: 3-32                   [16, 256, 14, 14]         --
```

---

```Bash
│    └─BasicBlock: 2-6                   [16, 256, 14, 14]         --
│    │    └─Conv2d: 3-33                 [16, 256, 14, 14]         589,824
│    │    └─BatchNorm2d: 3-34            [16, 256, 14, 14]         512
│    │    └─ReLU: 3-35                   [16, 256, 14, 14]         --
│    │    └─Conv2d: 3-36                 [16, 256, 14, 14]         589,824
│    │    └─BatchNorm2d: 3-37            [16, 256, 14, 14]         512
│    │    └─ReLU: 3-38                   [16, 256, 14, 14]         --
├─Sequential: 1-8                        [16, 512, 7, 7]           --
│    └─BasicBlock: 2-7                   [16, 512, 7, 7]           --
│    │    └─Conv2d: 3-39                 [16, 512, 7, 7]           1,179,648
│    │    └─BatchNorm2d: 3-40            [16, 512, 7, 7]           1,024
│    │    └─ReLU: 3-41                   [16, 512, 7, 7]           --
│    │    └─Conv2d: 3-42                 [16, 512, 7, 7]           2,359,296
│    │    └─BatchNorm2d: 3-43            [16, 512, 7, 7]           1,024
│    │    └─Sequential: 3-44             [16, 512, 7, 7]           132,096
│    │    └─ReLU: 3-45                   [16, 512, 7, 7]           --
│    └─BasicBlock: 2-8                   [16, 512, 7, 7]           --
│    │    └─Conv2d: 3-46                 [16, 512, 7, 7]           2,359,296
│    │    └─BatchNorm2d: 3-47            [16, 512, 7, 7]           1,024
│    │    └─ReLU: 3-48                   [16, 512, 7, 7]           --
│    │    └─Conv2d: 3-49                 [16, 512, 7, 7]           2,359,296
│    │    └─BatchNorm2d: 3-50            [16, 512, 7, 7]           1,024
│    │    └─ReLU: 3-51                   [16, 512, 7, 7]           --
├─AdaptiveAvgPool2d: 1-9                 [16, 512, 1, 1]           --
├─Linear: 1-10                           [16, 1000]                513,000
```

---

```Bash
==========================================================================================
Total params: 11,689,512
Trainable params: 11,689,512
Non-trainable params: 0
Total mult-adds (G): 29.03
==========================================================================================
Input size (MB): 9.63
Forward/backward pass size (MB): 635.96
Params size (MB): 46.76
Estimated Total Size (MB): 692.35
==========================================================================================
```

<!-- copy and paste till here -->

    </textarea>
    <script src="./layouts/remark-latest.min.js"></script>
    <script>
      var slideshow = remark.create({
        ratio: "16:9",
        highlightStyle: "github",
      });
    </script>
  </body>
</html>